{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stop = stopwords.words(\"english\")\n",
    "\n",
    "def tokenizer(text):\n",
    "    \n",
    "    # clean data\n",
    "    text = re.sub('<[^>]*>', '', text)  # remove html tag\n",
    "    emoticons = re.findall('(?::|;|=)(?:-)?(?:\\)|\\(|D|P)', text.lower())  # emotion icons, like :)\n",
    "    text = re.sub('[\\W]+', ' ', text.lower()) \\  # to lowercase with emoicons\n",
    "        + \" \".join(emoticons).replace(\"-\", \"\")\n",
    "    \n",
    "    tokenized = [w for w in  text.split() if w not in stop]  # split and remove stop-words\n",
    "    return tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def stream_docs(path):\n",
    "    \"\"\"get a streaming generator\"\"\"\n",
    "    with open(path, \"r\") as f:\n",
    "        next(f)  # skip header\n",
    "        for line in f:\n",
    "            text, label = line[:-3], int(line[-2])\n",
    "            yield text, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('\"I recently rented Twister, a movie I\\'d seen several years ago on TV, and it has aged well; I found myself laughing out loud several times at it and as weird as all these people are, by the end I profoundly cared about them. This is the sort of little movie that is made for a cult audience because, rather like Howdy\\'s gazpacho (well, I think that\\'s what it is), it\\'s an acquired taste: you have to be attuned to its peculiar wavelength. The production values might be charitably called inexpensive and the pace and atmosphere take a while to get settled, but the film has a \"\"look\"\", especially in some wonderful shots contrasting the dry flatness of the land with the cluttery nouveau-riche opulence of the mansion interior: Michael Almereyda had a good eye even then. Life with sodapop magnate Eugene Cleveland (Harry Dean Stanton) and his household (two adult children, a grandchild, and a housekeeper) seems so detached from life outside we could be in Gormenghast. Everyone in this film is wonderful (especially Suzy Amis and Crispin Glover as the directionless genius siblings Maureen and Howdy), inhabiting their roles so comfortably after a while you just buy the strange premise, that somehow, having survived the tornado and being apparently incapable of happiness, these people are lucky, and yet don\\'t know quite what to do with their luck. There are some truly great scenes: Eugene\\'s sudden confrontations first with his gold-digging children\\'s tv host girlfriend Virginia (an acidly pert Lois Chiles), then with his children; William S. Burroughs taking target practice in the barn and telling a story about a mysterious Jim; Maureen\\'s boyfriend Chris proving himself by battling a shed full of wasps cloaked in a tablecloth and doily and old fedora; Howdy, Violet, Maureen and Chris all sitting on the couch (the latter three in appropriately lightweight summer garments, the former in a red blazer and black leather rock\\'n\\'roll gear) staring at images of deserts on the huge tv, and contemplating the future (the images were done by Bill Viola, who did the backdrop video installation for Nine Inch Nails\\' last tour). Crispin Glover is predictably magnificent as Howdy: as always, he remains perfectly in character. Howdy has made a cult of his misery and brilliance; he\\'s like the Oscar Wilde of Kansas, striving to live up to his red velvet suit. Whether he\\'s thrashing away tunelessly yet loudly on an electric guitar, cracking a fullsize bullwhip while wearing an all-black cowboy outfit, demolishing a room, or even doing simple things like driving or pouring the aforementioned soup from a blender pitcher, he\\'s mesmerizing. If you like his work, you\\'ll like this.\"',\n",
       " 1)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(stream_docs(path=\"moive_data.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_minibatch(doc_stream, size):\n",
    "    docs, y = [], []\n",
    "    try:\n",
    "        for _ in range(size):\n",
    "            text, label = next(doc_stream)\n",
    "            docs.append(text)\n",
    "            y.append(label)\n",
    "    except StopIteration:\n",
    "        return None, None\n",
    "    return docs, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "# HashingVectorizer is data-independent\n",
    "# largest number of features is set to 2^21\n",
    "# By choosing a large number of features in the HashingVectorizer,\n",
    "# we reduce the chance to cause hash collisions but we also increase the number of \n",
    "# coefficients in our logistic regression model\n",
    "vect = HashingVectorizer(decode_error=\"ignore\", n_features=2**21, preprocessor=None, tokenizer=tokenizer)\n",
    "clf = SGDClassifier(loss=\"log\", random_state=1, n_iter=1)\n",
    "doc_stream = stream_docs(\"moive_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [##############################] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:01:47\n"
     ]
    }
   ],
   "source": [
    "import pyprind\n",
    "\n",
    "pbar = pyprind.ProgBar(45)\n",
    "\n",
    "\n",
    "classes = np.array([0, 1])\n",
    "for _ in range(45):\n",
    "    X_train, y_train = get_minibatch(doc_stream, size=1000)\n",
    "    if not X_train:\n",
    "        break\n",
    "    X_train = vect.transform(X_train)  # vectorize\n",
    "    clf.partial_fit(X_train, y_train, classes=classes)\n",
    "    pbar.update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.874\n"
     ]
    }
   ],
   "source": [
    "X_test, y_test = get_minibatch(doc_stream, size=5000)\n",
    "X_test = vect.transform(X_test)\n",
    "print(\"Accuracy: %.3f\" % clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = clf.partial_fit(X_test, y_test)  # update model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "\n",
    "dest = os.path.join(\"moiveclassifier\", \"pkl_objects\")\n",
    "if not os.path.exists(dest):\n",
    "    os.makedirs(dest)\n",
    "pickle.dump(stop, open(os.path.join(dest, \"stopwords.pkl\"), \"wb\"), protocol=4)\n",
    "pickle.dump(clf, open(os.path.join(dest, \"classifier.pkl\"), \"wb\"), protocol=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
